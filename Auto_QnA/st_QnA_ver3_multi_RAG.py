import streamlit as st  # Streamlit ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ë¶ˆëŸ¬ì˜´
from langchain_openai import ChatOpenAI
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.vectorstores import FAISS
from langchain.chains import ConversationalRetrievalChain
from langchain.document_loaders import PyPDFLoader
import os

# í˜ì´ì§€ ê¸°ë³¸ ì„¤ì •
st.set_page_config(
    page_title="AI ê¸°ë°˜ ê³ ê° ì‘ëŒ€ ì„œë¹„ìŠ¤",  # ë¸Œë¼ìš°ì € íƒ­ì— í‘œì‹œí•  í˜ì´ì§€ ì œëª©
    page_icon="ğŸŒ",  # í˜ì´ì§€ íƒ­ì— í‘œì‹œí•  ì§€êµ¬ë³¸ ì•„ì´ì½˜
    layout="centered"  # í˜ì´ì§€ ë ˆì´ì•„ì›ƒì„ ì¤‘ì•™ì— ì •ë ¬í•˜ì—¬ ëª¨ë°”ì¼ ì±„íŒ… ìŠ¤íƒ€ì¼ë¡œ êµ¬ì„±
)

# ëŒ€í™” íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”
if "chat_history" not in st.session_state:
    st.session_state["chat_history"] = []  # ëŒ€í™” íˆìŠ¤í† ë¦¬ìš© ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”

if "memory" not in st.session_state:
    st.session_state["memory"] = []

if 'retriever' not in st.session_state:
    # ì‚¬ì „ì— ì •ì˜ëœ ë¬¸ì„œ ê²½ë¡œ ëª©ë¡
    document_paths = ["Auto_QnA/docs/ma2155_iphone-15-info.pdf", 
                      "Auto_QnA/docs/iPhone ìˆ˜ë¦¬ ë° ì„œë¹„ìŠ¤ - Apple ì§€ì› (KR).pdf"] # ì—¬ê¸°ì„œ ê²½ë¡œë¥¼ ì„¤ì •í•˜ì—¬ ë°±ì—”ë“œì—ì„œ ë¬¸ì„œë¥¼ ê°€ì ¸ì˜´
    all_documents = []
    for path in document_paths:
        if os.path.exists(path):
            loader = PyPDFLoader(path)
            data = loader.load()
            all_documents.extend(data)

    embeddings = OpenAIEmbeddings()
    vectors = FAISS.from_documents(all_documents, embeddings)
    st.session_state['retriever'] = vectors.as_retriever()

# ìƒë‹¨ í—¤ë” ì„¤ì •
st.markdown("""
    <div style="background-color:#4A90E2;padding:10px;border-radius:10px;">
        <h1 style="color:white;text-align:center;"> ğŸ¤– AI ê³ ê° ì‘ëŒ€ ì„œë¹„ìŠ¤</h1>
    </div>
""", unsafe_allow_html=True)  # HTMLë¡œ ìƒë‹¨ í—¤ë” ì˜ì—­ì˜ ë°°ê²½ê³¼ ìƒ‰ìƒ ìŠ¤íƒ€ì¼ë§

# ì±„íŒ… ìŠ¤íƒ€ì¼ì˜ UI êµ¬ì„±
# ChatOpenAI ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ë‹µë³€ ìƒì„± ë° ë©”ëª¨ë¦¬ ì¶”ê°€
def generate_response(input_text): 
    # ChatOpenAI ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    llm = ChatOpenAI(
        temperature=1.0,  # ì‘ë‹µì˜ ì°½ì˜ì„±ì„ ìµœì†Œí™”í•˜ì—¬ ì¼ê´€ì„± ìˆëŠ” ë‹µë³€ ì œê³µ
        model_name='gpt-4o-mini'  # ì‚¬ì „ ì§€ì •ëœ AI ëª¨ë¸ ì‚¬ìš©
    )
    
    if 'retriever' in st.session_state:
        # RAG ì²´ì¸ì„ ì‚¬ìš©í•˜ì—¬ ë‹µë³€ ìƒì„±
        chain = ConversationalRetrievalChain.from_llm(
            llm=llm,
            retriever=st.session_state['retriever'],
            return_source_documents=False
        )
        
        # ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ ì…ë ¥ìœ¼ë¡œ ì „ë‹¬
        result = chain({
            "question": input_text,
            "chat_history": []  # í•­ìƒ ìƒˆë¡œìš´ ì§ˆë¬¸ìœ¼ë¡œ ê°„ì£¼í•˜ì—¬ ë‹µë³€ ìƒì„±
        })
        response = result['answer']
    else:
        # ë©”ëª¨ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹µë³€ ìƒì„±
        memory_summary = "\n".join(
            [f"User: {q}\nAI: {a}" for q, a in st.session_state['chat_history']]
        )
        full_input = f"{memory_summary}\nUser: {input_text}\nAI:"
        response = llm.predict(full_input)
    
    # ëŒ€í™” íˆìŠ¤í† ë¦¬ì— ì €ì¥
    st.session_state['chat_history'].append(("User", input_text))
    st.session_state['chat_history'].append(("AI", response))
    
    return response  # ì‘ë‹µ ë°˜í™˜

# ì‚¬ìš©ì ì…ë ¥ì„ ë°›ëŠ” í¼ ìƒì„±
with st.form("question_form"):  # í¼ì„ ìƒì„±í•˜ì—¬ ì‚¬ìš©ì ì§ˆë¬¸ì„ ë°›ìŒ
    text = st.text_input(
        "ê¶ê¸ˆí•œ ì ì„ ì…ë ¥í•˜ì„¸ìš”:", 
        placeholder="ì˜ˆ: ì•„ì´í° ê¸°ëŠ¥ì— ëŒ€í•´ì„œ ê°„ë‹¨í•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
    )  # í…ìŠ¤íŠ¸ ì…ë ¥ í•„ë“œ ìƒì„±
    submitted = st.form_submit_button("ë³´ë‚´ê¸°", use_container_width=True)  # 'ë³´ë‚´ê¸°' ë²„íŠ¼ ìƒì„±í•˜ì—¬ í¼ ì œì¶œ

    # ì‚¬ìš©ìê°€ ì§ˆë¬¸ì„ ì œì¶œí–ˆì„ ë•Œ ë‹µë³€ ìƒì„±
    if submitted and text.strip():
        response = generate_response(text)  # ì‘ë‹µ ìƒì„± í•¨ìˆ˜ í˜¸ì¶œ
    elif submitted:
        st.warning("ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")

# ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¶œë ¥ (ìµœì‹  ëŒ€í™”ê°€ ìœ„ë¡œ ì¶œë ¥ë˜ë„ë¡ ì„¤ì •)
chat_history_reversed = st.session_state["chat_history"][::-1]  # ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ ì—­ìˆœìœ¼ë¡œ ë³€ê²½
for speaker, message in chat_history_reversed:
    if speaker == "User":
        st.markdown(f"""
            <div style="background-color:#DCF8C6;padding:10px;border-radius:10px;margin-top:10px;width:80%;margin-left:auto;">
                <p><strong>ê³ ê°ë‹˜:</strong> {message}</p>
            </div>
        """, unsafe_allow_html=True)  # ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ìŠ¤íƒ€ì¼ë§í•˜ì—¬ í‘œì‹œ
    else:
        st.markdown(f"""
            <div style="background-color:#F0F0F0;padding:10px;border-radius:10px;margin-top:10px;width:80%;">
                <p><strong>ğŸ’¡ AI ì‘ë‹µ:</strong> {message}</p>
            </div>
        """, unsafe_allow_html=True)  # AI ì‘ë‹µì„ ìŠ¤íƒ€ì¼ë§í•˜ì—¬ í‘œì‹œ

# í‘¸í„° ì¶”ê°€
st.markdown("""
    <div style="margin-top: 50px; padding: 15px; background-color: #333; color: white; text-align: center; border-radius: 10px;">
        <p>Powered by LangChain & OpenAI API | ğŸ¦ ê³ ê°ì˜ ë§Œì¡±ì„ ìœ„í•´ ì–¸ì œë‚˜ ìµœì„ ì„ ë‹¤í•©ë‹ˆë‹¤.</p>
    </div>
""", unsafe_allow_html=True)  # í˜ì´ì§€ í•˜ë‹¨ì— í‘¸í„° í‘œì‹œ (ìŠ¤íƒ€ì¼ë§ ì ìš©)
