import streamlit as st
import pandas as pd
import numpy as np
from datetime import datetime
import seaborn as sns
import matplotlib.pyplot as plt
from matplotlib import font_manager, rc
import os
from langchain_openai import ChatOpenAI
from langchain.document_loaders import PyPDFLoader

# LangChainê³¼ OpenAI API ì„í¬íŠ¸
from langchain import PromptTemplate
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.vectorstores import FAISS

# ì„¤ì¹˜í•œ í°íŠ¸ ê²½ë¡œ ì„¤ì •
font_path = '/usr/share/fonts/truetype/nanum/NanumGothic.ttf'
font_name = font_manager.FontProperties(fname=font_path).get_name()
rc('font', family=font_name)
plt.rcParams['axes.unicode_minus'] = False

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="LLM ì—ë„ˆì§€ ìµœì í™” ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ", layout="wide")

# í—¤ë”
st.title("ğŸ”‹ LLM ì—ë„ˆì§€ ìµœì í™” ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ")
st.markdown("ì‹¤ì‹œê°„ìœ¼ë¡œ LLMì˜ ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ê³¼ ìµœì í™” ìƒíƒœë¥¼ ëª¨ë‹ˆí„°ë§í•©ë‹ˆë‹¤.")

# ì‚¬ì´ë“œë°” - ë‚ ì§œ ì„ íƒ
st.sidebar.header("ğŸ“… ë‚ ì§œ í•„í„°")
start_date = st.sidebar.date_input("ì‹œì‘ ë‚ ì§œ", pd.to_datetime('2016-04-01'))
end_date = st.sidebar.date_input("ì¢…ë£Œ ë‚ ì§œ", pd.to_datetime('2016-04-15'))

if start_date > end_date:
    st.sidebar.error("ì‹œì‘ ë‚ ì§œê°€ ì¢…ë£Œ ë‚ ì§œë³´ë‹¤ ëŠ¦ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
@st.cache_data
def load_data(file_path):
    data = pd.read_csv(file_path, parse_dates=['date'], index_col='date')
    return data

data = load_data("Energy_Optimization/data/KAG_energydata_complete.csv")

# ë‚ ì§œ í•„í„° ì ìš©
filtered_data = data[(data.index >= pd.to_datetime(start_date)) & (data.index <= pd.to_datetime(end_date))]

# ë©”ì¸ ì—´ì—ì„œ ë ˆì´ì•„ì›ƒ ì„¤ì •
col1, col2 = st.columns(2)

# ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ì¶”ì´ ê·¸ë˜í”„
col1.subheader("âš¡ ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ì¶”ì´")
col1.line_chart(filtered_data['Appliances'])

# ìµœì í™” ìˆ˜ì¤€ ì¶”ì´ ê·¸ë˜í”„ (ê¸°ì˜¨ ë°ì´í„°ë¥¼ ìµœì í™” ìˆ˜ì¤€ìœ¼ë¡œ ì‚¬ìš©)
col2.subheader("ğŸ“ˆ ê¸°ì˜¨ ìˆ˜ì¤€ ì¶”ì´")
col2.line_chart(filtered_data['T1'])

# ì§€í‘œ í‘œì‹œ
st.markdown("---")
st.header("í˜„ì¬ ìƒíƒœ ì§€í‘œ")

col3, col4 = st.columns(2)
current_energy = filtered_data['Appliances'].iloc[-1]
current_optimization = filtered_data['T1'].iloc[-1]

col3.metric(label="í˜„ì¬ ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ (Wh)", value=f"{current_energy:.2f}")
col4.metric(label="í˜„ì¬ ìµœì í™” ìˆ˜ì¤€ (ê¸°ì˜¨)", value=f"{current_optimization:.2f}")

# ëª©í‘œ ì„¤ì •ê°’ì„ ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ê·¸ë˜í”„ì— ì„ ìœ¼ë¡œ í‘œì‹œ
st.markdown("---")
st.header("í‰ê·  ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ê³¼ ëª©í‘œ ë¹„êµ")
user_goal = st.sidebar.number_input("ì—ë„ˆì§€ ì‚¬ìš© ëª©í‘œ (Wh)", min_value=0, value=400, step=50)
fig2, ax2 = plt.subplots(figsize=(10, 6))
ax2.plot(filtered_data.index, filtered_data['Appliances'], label='ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰', color='blue')
ax2.axhline(y=user_goal, color='red', linestyle='--', label='ì‚¬ìš©ì ëª©í‘œ')
ax2.set_ylabel("ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ (Wh)")
ax2.set_title("ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ê³¼ ëª©í‘œ ë¹„êµ")
ax2.legend()
st.pyplot(fig2)

# ì‹œê°„ëŒ€ë³„ ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ íˆíŠ¸ë§µ
st.markdown("---")
st.header("ì‹œê°„ëŒ€ë³„ ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ íˆíŠ¸ë§µ")
fig, ax = plt.subplots(figsize=(10, 6))
pivot_data = filtered_data.copy()
pivot_data['hour'] = pivot_data.index.hour
pivot_data['day'] = pivot_data.index.date
pivot_table = pivot_data.pivot_table(index='hour', columns='day', values='Appliances', aggfunc='mean')
sns.heatmap(pivot_table, cmap="YlGnBu", ax=ax)
st.pyplot(fig)

# --- RAG ê¸°ëŠ¥ ì¶”ê°€ ë¶€ë¶„ ì‹œì‘ ---
st.markdown("---")
st.header("ğŸ“Š ë°ì´í„° ë¶„ì„ ë¦¬í¬íŠ¸")

# ë°ì´í„° ë¶„ì„ ê²°ê³¼ ìš”ì•½ ìƒì„±
def generate_analysis_summary(data):
    energy_mean = data['Appliances'].mean()
    energy_max = data['Appliances'].max()
    energy_min = data['Appliances'].min()
    temp_mean = data['T1'].mean()
    summary = f"""
    ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ì˜ í‰ê· ì€ {energy_mean:.2f}Wh ì…ë‹ˆë‹¤.
    ìµœëŒ€ ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ì€ {energy_max:.2f}Wh ì´ë©°, ìµœì†Œ ì‚¬ìš©ëŸ‰ì€ {energy_min:.2f}Wh ì…ë‹ˆë‹¤.
    í‰ê·  ì‹¤ë‚´ ì˜¨ë„ëŠ” {temp_mean:.2f}Â°C ì…ë‹ˆë‹¤.
    """
    return summary

# ê·¸ë˜í”„ ë°ì´í„° ìš”ì•½ í•¨ìˆ˜
def generate_graph_summary(data):
    # ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ì¶”ì´ ìš”ì•½
    energy_trend = "ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ì¶”ì´ì—ì„œ ì „ë°˜ì ìœ¼ë¡œ ì¼ì •í•œ ì‚¬ìš©ëŸ‰ì´ ìœ ì§€ë˜ì—ˆìœ¼ë‚˜, ì¼ë¶€ ê¸°ê°„ ë™ì•ˆ ê¸‰ê²©í•œ ì¦ê°€ê°€ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤." \
                   if data['Appliances'].std() > 10 else "ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ì´ ì¼ì •í•˜ê²Œ ìœ ì§€ë˜ê³  ìˆìŠµë‹ˆë‹¤."
    
    # ê¸°ì˜¨ ìˆ˜ì¤€ ì¶”ì´ ìš”ì•½
    temperature_trend = f"ê¸°ì˜¨ ìˆ˜ì¤€ì˜ í‰ê· ì€ {data['T1'].mean():.2f}Â°Cë¡œ ìœ ì§€ë˜ê³  ìˆìŠµë‹ˆë‹¤."

    # íˆíŠ¸ë§µ ìš”ì•½
    pivot_data = data.copy()
    pivot_data['hour'] = pivot_data.index.hour
    pivot_data['day'] = pivot_data.index.date
    pivot_table = pivot_data.pivot_table(index='hour', columns='day', values='Appliances', aggfunc='mean')
    highest_usage_hour = pivot_table.mean(axis=1).idxmax()
    heatmap_summary = f"ì‹œê°„ëŒ€ë³„ ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ íˆíŠ¸ë§µì—ì„œ ê°€ì¥ ë†’ì€ ì‚¬ìš©ëŸ‰ì€ {highest_usage_hour}ì‹œì— ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤."

    summary = f"""
    ê·¸ë˜í”„ ë¶„ì„ ìš”ì•½:
    - {energy_trend}
    - {temperature_trend}
    - {heatmap_summary}
    """
    return summary

# ê¸°ì¡´ ë°ì´í„° ë¶„ì„ ìš”ì•½ ìƒì„±
analysis_summary = generate_analysis_summary(filtered_data)

# ê·¸ë˜í”„ ìš”ì•½ ìƒì„±
graph_summary = generate_graph_summary(filtered_data)

# ë²¡í„° ìŠ¤í† ì–´ì— ì €ì¥í•  ë¬¸ì„œ ìƒì„±
data_docs = [analysis_summary, graph_summary]

# ì„ë² ë”© ìƒì„± ë° ë²¡í„° ìŠ¤í† ì–´ êµ¬ì¶•
embeddings = OpenAIEmbeddings()
data_vectorstore = FAISS.from_texts(data_docs, embeddings)

# ì‚¬ì „ì— ì •ì˜ëœ ë¬¸ì„œ ê²½ë¡œ ëª©ë¡
document_paths = ["Energy_Optimization/docs/data_description.pdf", 
                "Energy_Optimization/docs/optimization_paper.pdf"] # ì—¬ê¸°ì„œ ê²½ë¡œë¥¼ ì„¤ì •í•˜ì—¬ ë°±ì—”ë“œì—ì„œ ë¬¸ì„œë¥¼ ê°€ì ¸ì˜´
all_documents = []
for path in document_paths:
    if os.path.exists(path):
        loader = PyPDFLoader(path)
        data = loader.load()
        all_documents.extend(data)

doc_vectorstore = FAISS.from_documents(all_documents, embeddings)

# LLM ì„¤ì •
llm = ChatOpenAI(temperature=0.7, model='gpt-4o-mini')

# ì¢…í•© ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±
st.subheader("ğŸ“„ ì¢…í•© ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ë¶„ì„ ë¦¬í¬íŠ¸")

# ë¬¸ì„œì—ì„œ ê´€ë ¨ ë‚´ìš© ê²€ìƒ‰
query = "ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ë¶„ì„ ë³´ê³ ì„œ"
docs = doc_vectorstore.similarity_search(query, k=2)
doc_texts = "\n".join([doc.page_content for doc in docs])

# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„¤ì •
prompt_template = PromptTemplate(
    input_variables=["analysis_summaries", "document_texts"],
    template="""
    ë‹¹ì‹ ì€ ì—ë„ˆì§€ ë°ì´í„° ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
    ì•„ë˜ëŠ” ì—ë„ˆì§€ ë°ì´í„° ë¶„ì„ ê²°ê³¼ ìš”ì•½ì…ë‹ˆë‹¤:

    {analysis_summaries}

    ì•„ë˜ëŠ” ê´€ë ¨ ë¬¸ì„œë“¤ì…ë‹ˆë‹¤:

    {document_texts}

    ìœ„ì˜ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ, ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ì— ëŒ€í•œ ì¢…í•©ì ì¸ ë¶„ì„ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.
    ë¦¬í¬íŠ¸ì—ëŠ” ì—ë„ˆì§€ ì‚¬ìš© ì¶”ì´, íŒ¨í„´, ì¸ì‚¬ì´íŠ¸, ê·¸ë¦¬ê³  ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ì¶”ì²œ ì‚¬í•­ì„ í¬í•¨í•´ì£¼ì„¸ìš”.
    """
)

prompt = prompt_template.format(
    analysis_summaries=analysis_summary + "\n" + graph_summary,
    document_texts=doc_texts
)

# ë¦¬í¬íŠ¸ ìƒì„±
report = llm.predict(prompt)
st.write(report)

# ì‚¬ìš©ì ì§ˆë¬¸ ì…ë ¥
st.subheader("ë¦¬í¬íŒ… ì„œë¹„ìŠ¤ ê´€ë ¨ ì¶”ê°€ ì§ˆë¬¸:")
user_question = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”", placeholder="ì˜ˆ: ì´ë²ˆ ê¸°ê°„ ë™ì•ˆ ì—ë„ˆì§€ ì‚¬ìš© íŒ¨í„´ì€ ì–´ë– í–ˆë‚˜ìš”?")

if user_question:
    # ìœ ì‚¬í•œ ë¬¸ì„œ(ë°ì´í„° ë¶„ì„ ê²°ê³¼) ê²€ìƒ‰
    docs = data_vectorstore.similarity_search(user_question)
    relevant_doc = docs[0]

    # ìœ ì‚¬í•œ ë¬¸ì„œ(ì°¸ê³  ë¬¸ì„œ) ê²€ìƒ‰
    docs2 = doc_vectorstore.similarity_search(user_question)
    relevant_doc2 = docs2[0]

    # LLMì„ ì‚¬ìš©í•˜ì—¬ ë‹µë³€ ìƒì„±
    prompt_template = PromptTemplate(
        input_variables=["context", "context2", "question"],
        template="""
        ì•„ë˜ëŠ” ì—ë„ˆì§€ ë°ì´í„° ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤:

        {context}
        
        ì•„ë˜ëŠ” ê´€ë ¨ ë¬¸ì„œ ì •ë³´ì…ë‹ˆë‹¤:

        {context2}

        ì§ˆë¬¸: {question}

        ìœ„ì˜ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.
        """
    )
    prompt = prompt_template.format(context=relevant_doc, context2=relevant_doc2, question=user_question)
    answer = llm.predict(prompt)
    st.write("**ë‹µë³€:**")
    st.write(answer)
# --- RAG ê¸°ëŠ¥ ì¶”ê°€ ë¶€ë¶„ ë ---

# í‘¸í„°
st.markdown("---")
st.markdown("Â© LLM ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ")