import streamlit as st  # Streamlit ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ë¶ˆëŸ¬ì˜´
from langchain_openai import ChatOpenAI
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.vectorstores import FAISS
from langchain.document_loaders import PyPDFLoader
from langchain.chains import ConversationalRetrievalChain
import tempfile

# í˜ì´ì§€ ê¸°ë³¸ ì„¤ì •
st.set_page_config(
    page_title="ì»¤ìŠ¤í…€ ì±—ë´‡ í˜ì´ì§€ ì œëª©",  # ë¸Œë¼ìš°ì € íƒ­ì— í‘œì‹œí•  í˜ì´ì§€ ì œëª©
    page_icon="ğŸ¤–",  # í˜ì´ì§€ íƒ­ì— í‘œì‹œí•  ì•„ì´ì½˜
    layout="centered"  # í˜ì´ì§€ ë ˆì´ì•„ì›ƒì„ ê°€ìš´ë° ì •ë ¬ë¡œ ì„¤ì •
)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "chat_history" not in st.session_state:
    st.session_state["chat_history"] = []  # ëŒ€í™” íˆìŠ¤í† ë¦¬ìš© ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”

if "memory" not in st.session_state:
    st.session_state["memory"] = []

if 'history' not in st.session_state:
    st.session_state['history'] = []

# í˜ì´ì§€ í—¤ë” ì„¤ì •
st.title("ğŸ¤– AIë¡œ ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”!")  # í˜ì´ì§€ íƒ€ì´í‹€ í‘œì‹œ
st.markdown("### AIì™€ í•¨ê»˜ ê¶ê¸ˆì¦ì„ í•´ê²°í•´ ë³´ì„¸ìš”. ì•„ë˜ì— ì§ˆë¬¸ì„ ì…ë ¥í•˜ê³  **ë³´ë‚´ê¸°** ë²„íŠ¼ì„ ëˆŒëŸ¬ë³´ì„¸ìš”!")  # ì„œë¸Œ íƒ€ì´í‹€ í‘œì‹œ

# ì‘ë‹µ ë‹¤ì–‘ì„± ì„¤ì • ìŠ¬ë¼ì´ë” ì¶”ê°€ (temperature ì¡°ì •)
temperature = st.slider("ì‘ë‹µ ë‹¤ì–‘ì„± ì„¤ì • (Temperature)", 0.0, 1.0, 0.7, step=0.05)

# ëŒ€í™” ìŠ¤íƒ€ì¼ ì„ íƒ ì˜µì…˜ ì¶”ê°€
style = st.selectbox("ëŒ€í™” ìŠ¤íƒ€ì¼ ì„ íƒ", ("ì •ì¤‘í•œ", "ì¼ìƒì ", "ì „ë¬¸ì "))

# ì‚¬ì´ë“œë°”ì— íŒŒì¼ ì—…ë¡œë“œ ê¸°ëŠ¥ ì¶”ê°€
uploaded_file = st.sidebar.file_uploader("PDF íŒŒì¼ ì—…ë¡œë“œ", type="pdf")

if uploaded_file:
    with tempfile.NamedTemporaryFile(delete=False) as tmp_file:
        tmp_file.write(uploaded_file.getvalue())
        tmp_file_path = tmp_file.name

    loader = PyPDFLoader(tmp_file_path)
    data = loader.load()

    embeddings = OpenAIEmbeddings()
    vectors = FAISS.from_documents(data, embeddings)

    # ë¦¬íŠ¸ë¦¬ë²„ë¥¼ ì„¸ì…˜ ìƒíƒœì— ì €ì¥
    st.session_state['retriever'] = vectors.as_retriever()

# ChatOpenAI ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ë‹µë³€ ìƒì„± ë° ë©”ëª¨ë¦¬ ì¶”ê°€
def generate_response(input_text): 
    # ëŒ€í™” ìŠ¤íƒ€ì¼ì— ë”°ë¼ í”„ë¡¬í”„íŠ¸ ì¡°ì •
    style_prefix = {
        "ì •ì¤‘í•œ": "ì •ì¤‘í•˜ê²Œ",
        "ì¼ìƒì ": "í¸í•˜ê²Œ",
        "ì „ë¬¸ì ": "ì „ë¬¸ì ìœ¼ë¡œ"
    }
    style_instruction = style_prefix[style]

    # ChatOpenAI ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    llm = ChatOpenAI(
        temperature=temperature,
        model_name='gpt-4o-mini'
    )

    if 'retriever' in st.session_state:
        # RAG ì²´ì¸ì„ ì‚¬ìš©í•˜ì—¬ ë‹µë³€ ìƒì„±
        chain = ConversationalRetrievalChain.from_llm(
            llm=llm,
            retriever=st.session_state['retriever'],
            return_source_documents=False
        )

        # ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ ì…ë ¥ìœ¼ë¡œ ì „ë‹¬
        result = chain({
            "question": input_text,
            "chat_history": st.session_state['history']
        })
        response = result['answer']

        # ëŒ€í™” íˆìŠ¤í† ë¦¬ì— ì €ì¥
        st.session_state['history'].append((input_text, response))
    else:
        # ë©”ëª¨ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹µë³€ ìƒì„±
        memory_summary = "\n".join(
            [f"User: {q}\nAI: {a}" for q, a in st.session_state['history']]
        )
        full_input = f"{memory_summary}\n[{style_instruction}] User: {input_text}\nAI:"
        response = llm.predict(full_input)

        # ëŒ€í™” íˆìŠ¤í† ë¦¬ì— ì €ì¥
        st.session_state['history'].append((input_text, response))

    return response  # ì‘ë‹µ ë°˜í™˜

# ì‚¬ìš©ì ì…ë ¥ì„ ë°›ëŠ” í¼ ìƒì„± (ë§¨ ì•„ë˜ì— ì…ë ¥ì°½ ìœ ì§€)
text = st.text_input("ê¶ê¸ˆí•œ ì ì„ ì…ë ¥í•˜ì„¸ìš”:", placeholder="ì˜ˆ: OpenAIì˜ í…ìŠ¤íŠ¸ ëª¨ë¸ ì¢…ë¥˜ëŠ” ì–´ë–¤ ê²ƒì´ ìˆë‚˜ìš”?")
submitted = st.button("ë³´ë‚´ê¸°")  # 'ë³´ë‚´ê¸°' ë²„íŠ¼ ìƒì„±í•˜ì—¬ ì œì¶œ

# ì‚¬ìš©ìê°€ ì§ˆë¬¸ì„ ì œì¶œí–ˆì„ ë•Œ ë‹µë³€ ìƒì„±
if submitted and text:
    response = generate_response(text)  # ì‘ë‹µ ìƒì„± í•¨ìˆ˜ í˜¸ì¶œ
    st.session_state["chat_history"].append(("User", text))
    st.session_state["chat_history"].append(("AI", response))

# ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¶œë ¥ (ì…ë ¥ì°½ ìœ„ë¡œ ì¶œë ¥ë˜ë„ë¡ ìˆ˜ì •)
chat_history_reversed = st.session_state["chat_history"][::-1]
for speaker, message_text in chat_history_reversed:
    if speaker == "User":
        st.write(f"**User:** {message_text}")
    else:
        st.info(f"**AI:** {message_text}")

# í‘¸í„° ì¶”ê°€ (ì„ íƒ ì‚¬í•­)
st.markdown("---")
st.caption("Powered by LangChain & OpenAI API")
